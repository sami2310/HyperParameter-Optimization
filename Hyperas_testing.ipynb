{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperas_testing",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "1RynV5txQHX8",
        "colab_type": "code",
        "outputId": "22c0b159-f0d8-4e6d-a13f-8f18e12666f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1261
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install hyperas\n",
        "!pip install hyperopt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hyperas\n",
            "  Downloading https://files.pythonhosted.org/packages/54/72/5533b6bf9b47dc33685c3e62c391d6eab5785a648a5ffa841e240a3db3fe/hyperas-0.4.tar.gz\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from hyperas) (2.2.4)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.1.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.2.3)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from hyperas) (1.0.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from hyperas) (4.4.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.4.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.11.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.14.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.0.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.0.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (2.8.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (3.7.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (0.16.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.2.2)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (6.0.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (7.4.2)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.4.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.6.1)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.3.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.4.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.1.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.4.2)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (3.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.10)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt->hyperas) (4.3.0)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (4.5.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (5.2.4)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (0.8.1)\n",
            "Collecting prompt-toolkit<2.1.0,>=2.0.0 (from jupyter-console->jupyter->hyperas)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/e6/adb3be5576f5d27c6faa33f1e9fea8fe5dbd9351db12148de948507e352c/prompt_toolkit-2.0.7-py3-none-any.whl (338kB)\n",
            "\u001b[K    100% |████████████████████████████████| 348kB 23.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (3.4.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->nbconvert->hyperas) (1.1.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook->jupyter->hyperas) (17.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook->jupyter->hyperas) (2.5.3)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter->hyperas) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->jupyter-console->jupyter->hyperas) (0.1.7)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (4.6.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (40.6.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (0.7.5)\n",
            "Building wheels for collected packages: hyperas\n",
            "  Running setup.py bdist_wheel for hyperas ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/06/38/3f/27826f57fae60ef788ceb47e2c649590ab8af31f42075325d2\n",
            "Successfully built hyperas\n",
            "\u001b[31mipython 5.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.4, but you'll have prompt-toolkit 2.0.7 which is incompatible.\u001b[0m\n",
            "\u001b[31mcufflinks 0.14.6 has requirement plotly>=3.0.0, but you'll have plotly 1.12.12 which is incompatible.\u001b[0m\n",
            "Installing collected packages: hyperas, prompt-toolkit\n",
            "  Found existing installation: prompt-toolkit 1.0.15\n",
            "    Uninstalling prompt-toolkit-1.0.15:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.15\n",
            "Successfully installed hyperas-0.4 prompt-toolkit-2.0.7\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (0.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.11.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt) (3.7.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt) (2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.14.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.1.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt) (4.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YkmiRHm_W84F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5574cb7-9f2e-4c75-9f0a-02973ec841a0"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "xl8-O0vGQPqa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data():\n",
        "    '''\n",
        "    Data providing function:\n",
        "    This function is separated from model() so that hyperopt\n",
        "    won't reload data for each evaluation run.\n",
        "    '''\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    X_train = X_train.reshape(60000, 784)\n",
        "    X_test = X_test.reshape(10000, 784)\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "    X_train /= 255\n",
        "    X_test /= 255\n",
        "    nb_classes = 10\n",
        "    Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "    Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "    return X_train, Y_train, X_test, Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n2CePOBvQ_3O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model(X_train, Y_train, X_test, Y_test):\n",
        "    '''\n",
        "    Model providing function:\n",
        "    Create Keras model with double curly brackets dropped-in as needed.\n",
        "    Return value has to be a valid python dictionary with two customary keys:\n",
        "        - loss: Specify a numeric evaluation metric to be minimized\n",
        "        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
        "    The last one is optional, though recommended, namely:\n",
        "        - model: specify the model just created so that we can later use it again.\n",
        "    '''\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, input_shape=(784,)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\n",
        "    model.add(Dense({{choice([256, 512, 1024])}}))\n",
        "    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\n",
        "\n",
        "    # If we choose 'four', add an additional fourth layer\n",
        "    if {{choice(['three', 'four'])}} == 'four':\n",
        "        model.add(Dense(100))\n",
        "        model.add({{choice([Dropout(0.5), Activation('linear')])}})\n",
        "        model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}},\n",
        "                  metrics=['accuracy'])\n",
        "        \n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size={{choice([64, 128])}},\n",
        "              epochs=1,\n",
        "              verbose=2,\n",
        "              validation_data=(X_test, Y_test))\n",
        "    score, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "    print('Test accuracy:', acc)\n",
        "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D9529aLEWViy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2771
        },
        "outputId": "0496182c-bb48-454b-d5dd-6a98b944935e"
      },
      "cell_type": "code",
      "source": [
        "trials = Trials()\n",
        "best_run, best_model = optim.minimize(model=model, # the model\n",
        "                                          data=data, # the data generating function\n",
        "                                          max_evals=10, # number of iterations\n",
        "                                          algo=tpe.suggest,\n",
        "                                          notebook_name='Hyperas_testing', # This is important! Name of the notebook\n",
        "                                          trials=trials, # contains parameters and results for all runs\n",
        "                                          eval_space=True\n",
        "                                     )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "from __future__ import print_function\n",
            "\n",
            "try:\n",
            "    from hyperopt import Trials, STATUS_OK, tpe\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas import optim\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas.distributions import choice, uniform\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.models import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers.core import Dense, Dropout, Activation\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.datasets import mnist\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.utils import np_utils\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import pandas as pd\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
            "        'Dense': hp.choice('Dense', [256, 512, 1024]),\n",
            "        'Activation': hp.choice('Activation', ['relu', 'sigmoid']),\n",
            "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
            "        'Dropout_2': hp.choice('Dropout_2', ['three', 'four']),\n",
            "        'add': hp.choice('add', [Dropout(0.5), Activation('linear')]),\n",
            "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n",
            "        'batch_size': hp.choice('batch_size', [64, 128]),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "  1: \n",
            "  2: '''\n",
            "  3: Data providing function:\n",
            "  4: This function is separated from model() so that hyperopt\n",
            "  5: won't reload data for each evaluation run.\n",
            "  6: '''\n",
            "  7: (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
            "  8: X_train = X_train.reshape(60000, 784)\n",
            "  9: X_test = X_test.reshape(10000, 784)\n",
            " 10: X_train = X_train.astype('float32')\n",
            " 11: X_test = X_test.astype('float32')\n",
            " 12: X_train /= 255\n",
            " 13: X_test /= 255\n",
            " 14: nb_classes = 10\n",
            " 15: Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
            " 16: Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
            " 17: \n",
            " 18: \n",
            " 19: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "   1: def keras_fmin_fnct(space):\n",
            "   2: \n",
            "   3:     '''\n",
            "   4:     Model providing function:\n",
            "   5:     Create Keras model with double curly brackets dropped-in as needed.\n",
            "   6:     Return value has to be a valid python dictionary with two customary keys:\n",
            "   7:         - loss: Specify a numeric evaluation metric to be minimized\n",
            "   8:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
            "   9:     The last one is optional, though recommended, namely:\n",
            "  10:         - model: specify the model just created so that we can later use it again.\n",
            "  11:     '''\n",
            "  12:     model = Sequential()\n",
            "  13:     model.add(Dense(512, input_shape=(784,)))\n",
            "  14:     model.add(Activation('relu'))\n",
            "  15:     model.add(Dropout(space['Dropout']))\n",
            "  16:     model.add(Dense(space['Dense']))\n",
            "  17:     model.add(Activation(space['Activation']))\n",
            "  18:     model.add(Dropout(space['Dropout_1']))\n",
            "  19: \n",
            "  20:     # If we choose 'four', add an additional fourth layer\n",
            "  21:     if space['Dropout_2'] == 'four':\n",
            "  22:         model.add(Dense(100))\n",
            "  23:         model.add(space['add'])\n",
            "  24:         model.add(Activation('relu'))\n",
            "  25: \n",
            "  26:     model.add(Dense(10))\n",
            "  27:     model.add(Activation('softmax'))\n",
            "  28: \n",
            "  29:     model.compile(loss='categorical_crossentropy',\n",
            "  30:                   optimizer=space['optimizer'],\n",
            "  31:                   metrics=['accuracy'])\n",
            "  32:         \n",
            "  33:     model.fit(X_train, Y_train,\n",
            "  34:               batch_size=space['batch_size'],\n",
            "  35:               epochs=1,\n",
            "  36:               verbose=2,\n",
            "  37:               validation_data=(X_test, Y_test))\n",
            "  38:     score, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
            "  39:     print('Test accuracy:', acc)\n",
            "  40:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
            "  41: \n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 4s - loss: 1.6615 - acc: 0.4488 - val_loss: 0.7619 - val_acc: 0.8314\n",
            "Test accuracy: 0.8314\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 8s - loss: 2.1446 - acc: 0.2973 - val_loss: 0.6994 - val_acc: 0.8049\n",
            "Test accuracy: 0.8049\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 8s - loss: 1.9632 - acc: 0.3030 - val_loss: 0.6929 - val_acc: 0.8799\n",
            "Test accuracy: 0.8799\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 5s - loss: 0.7271 - acc: 0.7681 - val_loss: 0.1983 - val_acc: 0.9393\n",
            "Test accuracy: 0.9393\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 5s - loss: 0.5132 - acc: 0.8421 - val_loss: 0.1466 - val_acc: 0.9551\n",
            "Test accuracy: 0.9551\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 4s - loss: 2.7091 - acc: 0.1123 - val_loss: 2.1571 - val_acc: 0.4858\n",
            "Test accuracy: 0.4858\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 5s - loss: 0.2846 - acc: 0.9131 - val_loss: 0.1303 - val_acc: 0.9590\n",
            "Test accuracy: 0.959\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 5s - loss: 2.2314 - acc: 0.1823 - val_loss: 1.9596 - val_acc: 0.5650\n",
            "Test accuracy: 0.565\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 5s - loss: 0.4567 - acc: 0.8548 - val_loss: 0.1643 - val_acc: 0.9478\n",
            "Test accuracy: 0.9478\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 10s - loss: 0.2952 - acc: 0.9090 - val_loss: 0.1300 - val_acc: 0.9632\n",
            "Test accuracy: 0.9632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "41_GXUwXj0kJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "9a22f47a-2b99-4439-8751-276555ac3809"
      },
      "cell_type": "code",
      "source": [
        "# Get all the results ordered\n",
        "import pandas as pd\n",
        "df = pd.DataFrame()\n",
        "results =[]\n",
        "for trial in trials.trials:\n",
        "        vals = trial.get('misc').get('vals')\n",
        "        vals['result'] = - trial.get('result').get('loss')\n",
        "        results.append(vals)\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "df.sort_values(by='result',ascending = False).head(1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Activation</th>\n",
              "      <th>Dense</th>\n",
              "      <th>Dropout</th>\n",
              "      <th>Dropout_1</th>\n",
              "      <th>Dropout_2</th>\n",
              "      <th>add</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[1]</td>\n",
              "      <td>[2]</td>\n",
              "      <td>[0.4143619965361732]</td>\n",
              "      <td>[0.09225974322037533]</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.9632</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Activation Dense               Dropout              Dropout_1 Dropout_2  \\\n",
              "9        [1]   [2]  [0.4143619965361732]  [0.09225974322037533]       [1]   \n",
              "\n",
              "   add batch_size optimizer  result  \n",
              "9  [1]        [0]       [1]  0.9632  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "y4zmhTmAhSg9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "b7745a06-ea50-459b-a0a7-6daceccde0dd"
      },
      "cell_type": "code",
      "source": [
        "best_run"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Activation': 'sigmoid',\n",
              " 'Dense': 1024,\n",
              " 'Dropout': 0.4143619965361732,\n",
              " 'Dropout_1': 0.09225974322037533,\n",
              " 'Dropout_2': 'four',\n",
              " 'add': <keras.layers.core.Activation at 0x7fd2438b55f8>,\n",
              " 'batch_size': 64,\n",
              " 'optimizer': 'adam'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "gBOpbk10tlwC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}